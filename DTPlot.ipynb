{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed  16  missing values to -1\n",
      "----------------------------------------------\n",
      "uniformity_cell_shape is dropped\n",
      "----------------------------------------------\n",
      "max_depth =  1\n",
      "Avg accuracy =  0.14443953237056684\n",
      "max_depth =  2\n",
      "Avg accuracy =  0.7371794871794872\n",
      "max_depth =  3\n",
      "Avg accuracy =  0.9055530995186167\n",
      "max_depth =  4\n",
      "Avg accuracy =  0.9055530995186167\n",
      "max_depth =  5\n",
      "Avg accuracy =  0.9055530995186167\n",
      "max_depth =  6\n",
      "Avg accuracy =  0.9055530995186167\n",
      "max_depth =  7\n",
      "Avg accuracy =  0.9055530995186167\n",
      "max_depth =  8\n",
      "Avg accuracy =  0.9055530995186167\n",
      "max_depth =  9\n",
      "Avg accuracy =  0.9055530995186167\n",
      "max_depth =  10\n",
      "Avg accuracy =  0.9055530995186167\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "from preProcess import preProcess\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import Counter\n",
    "from testResults import testResults\n",
    "import numpy as np\n",
    "\n",
    "class node:\n",
    "    def __init__(self, attribute=None, depth=None):\n",
    "        self.depth = depth\n",
    "        self.children = [None] * 10\n",
    "        self.attribute = attribute\n",
    "        self.definiteLabel = None\n",
    "\n",
    "    def assign_child(self, attribute_value, child):\n",
    "        self.children[attribute_value] = child\n",
    "\n",
    "    def assign_label(self, label):\n",
    "        self.definiteLabel = label\n",
    "\n",
    "class decisionTree:\n",
    "    def __init__(self, criterion='entropy', max_depth=None, min_samples_split=2):\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree_built = False\n",
    "\n",
    "    def find_entropy(self, dataset):\n",
    "        numEntries = len(dataset)\n",
    "        labelCounts = Counter()\n",
    "        for i in range(numEntries):\n",
    "            labelCounts[dataset[i][-1]] += 1\n",
    "        shannonEntropy = 0\n",
    "        for label in labelCounts:\n",
    "            prob = float(labelCounts[label])/numEntries\n",
    "            shannonEntropy -= prob*log(prob, 2)\n",
    "        return shannonEntropy\n",
    "\n",
    "    def perform_split(self, dataset, axis, value):\n",
    "        newDataset = []\n",
    "        listDataset = list(dataset)\n",
    "        for sample in listDataset:\n",
    "            if sample[axis] == value:\n",
    "                reducedFeatureVector = list(sample[:axis])\n",
    "                reducedFeatureVector.extend(list(sample[axis+1:]))\n",
    "                newDataset.append(reducedFeatureVector)\n",
    "        return np.array(newDataset)\n",
    "\n",
    "    def chooseBestFeatureToSplit(self, dataset):\n",
    "        numFeatures = len(dataset[0])-1\n",
    "        baseEntropy = self.find_entropy(dataset)\n",
    "        bestInfoGain = 0\n",
    "        bestFeature = -1\n",
    "        for i in range(numFeatures):\n",
    "            entropyVal = 0\n",
    "            for value in range(1, 11):\n",
    "                subDataset = self.perform_split(dataset, i, value)\n",
    "                prob = len(subDataset) / float(len(dataset))\n",
    "                entropyVal += prob*self.find_entropy(subDataset)\n",
    "            infoGain = baseEntropy - entropyVal\n",
    "            if infoGain > bestInfoGain:\n",
    "                bestInfoGain = infoGain\n",
    "                bestFeature = i\n",
    "        return bestFeature\n",
    "\n",
    "    def returnClassProbabilities(self, dataset):\n",
    "        sampleCount = len(dataset)\n",
    "        labelCounts = Counter()\n",
    "        for i in range(sampleCount):\n",
    "            if dataset[i][-1] == 2:\n",
    "                labelCounts[2] += 1\n",
    "            else:\n",
    "                labelCounts[4] += 1\n",
    "        return [labelCounts[2]/float(sampleCount), labelCounts[4]/float(sampleCount)]\n",
    "\n",
    "    def recursiveBuild(self, dataNode, dataset):\n",
    "        probs = self.returnClassProbabilities(dataset)\n",
    "        probs = sorted(self.returnClassProbabilities(dataset), reverse=True)\n",
    "        if probs[0] > 90 or dataNode.depth == self.max_depth or len(dataset[0])<self.min_samples_split:\n",
    "            dataNode.assign_label(probs[0])\n",
    "            return\n",
    "\n",
    "        dataNode.labelSamples = [2,4][np.argmax(probs)]\n",
    "        for i in range(1, 11):\n",
    "            splitDataset = self.perform_split(dataset, dataNode.attribute, i)\n",
    "            if len(splitDataset):\n",
    "                best_feature = self.chooseBestFeatureToSplit(splitDataset)\n",
    "                if best_feature==-1:\n",
    "                    subProbs = self.returnClassProbabilities(splitDataset)\n",
    "                    dataNode.children[i-1] = node(depth = dataNode.depth+1)\n",
    "                    dataNode.children[i-1].assign_label([2,4][np.argmax(subProbs)])\n",
    "                else:    \n",
    "                    dataNode.children[i-1] = node(attribute=best_feature, depth = dataNode.depth+1)\n",
    "                    self.recursiveBuild(dataNode.children[i-1], splitDataset)\n",
    "\n",
    "    def fit(self, dataset):\n",
    "        self.tree_built = True\n",
    "        self.root = node(attribute = self.chooseBestFeatureToSplit(dataset), depth=0)\n",
    "        self.recursiveBuild(self.root, dataset)\n",
    "    \n",
    "    def predict(self, groups):\n",
    "        results = []\n",
    "        for group in groups:\n",
    "            results.append(self.predict_single(group))\n",
    "        return np.array(results)\n",
    "    \n",
    "    def predict_single(self, x):\n",
    "        available_features = list(x)\n",
    "        # print(available_features)\n",
    "        if self.tree_built:\n",
    "            pres_node = self.root\n",
    "            while pres_node.definiteLabel == None:\n",
    "                attribute = pres_node.attribute\n",
    "                if pres_node.children[available_features[attribute]-1]:\n",
    "                    pres_node = pres_node.children[available_features[attribute]-1]\n",
    "                    available_features.pop(attribute)\n",
    "                else: return pres_node.labelSamples\n",
    "                # print(available_features)\n",
    "        return pres_node.definiteLabel\n",
    "            \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    preProcessData = preProcess()\n",
    "    preProcessData.handle_missing_values()\n",
    "    preProcessData.handle_highly_correlated_features()\n",
    "    df = preProcessData.return_df()\n",
    "    accs = []\n",
    "    for i in range(1, 11):\n",
    "        avg_acc = 0\n",
    "        DT = decisionTree(max_depth=i)\n",
    "        kFold = KFold(6, True, 1)\n",
    "        values = df.values\n",
    "        for train, test in kFold.split(values):\n",
    "            # print(\"Taking %d train datapoints\" % len(train))\n",
    "            train_x = values[train]\n",
    "            test_x, test_y = values[test][:,:-1], values[test][:,-1]\n",
    "            DT.fit(train_x)\n",
    "            pred_y = DT.predict(test_x)\n",
    "            results = testResults(pred_y, test_y)\n",
    "            avg_acc += results.return_accuracy()\n",
    "            # print(\"Accuracy of model is \", results.return_accuracy())\n",
    "            # print('F Score of model is ', results.return_fscore())\n",
    "            # print(\"Confusion Matrix for the model :\\n\", confusion_matrix(test_y, pred_y))\n",
    "            # print()\n",
    "            # print(DT.predict_single(test_x[0]), test_y[0])\n",
    "        print(\"max_depth = \", i)\n",
    "        print(\"Avg accuracy = \", avg_acc/6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
